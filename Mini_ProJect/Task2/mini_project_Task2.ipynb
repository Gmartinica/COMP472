{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f1f40a",
   "metadata": {},
   "source": [
    "# Task2 Of Mini Project 1\n",
    "## AmirHossein Hadinezhad, Andrei Serban, Gabriel Alejandro Martinica Ardon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41002ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/1875585947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7539d7",
   "metadata": {},
   "source": [
    "### Loading the data (part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "265e9606",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/793836825.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drug200.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#debug lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(np.count_nonzero(dataset==np.nan))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(dataset.head())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"drug200.csv\")\n",
    "#debug lines\n",
    "# print(np.count_nonzero(dataset==np.nan))\n",
    "# print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d3acd",
   "metadata": {},
   "source": [
    "### Distribution Graph (Part3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4026e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/2911793833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistributation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDrug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# dataset[-1].plot(kind='hist');\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistributation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistributation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "distributation = dataset.Drug.value_counts()\n",
    "\n",
    "# dataset[-1].plot(kind='hist');\n",
    "y = distributation.values\n",
    "x = distributation.index\n",
    "plt.plot()\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Drug Type')\n",
    "plt.bar(x, y)\n",
    "plt.suptitle(\"Drug Distributation\")\n",
    "plt.savefig(\"Drug Distributation.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e02eac",
   "metadata": {},
   "source": [
    "### Convering the data  (Part4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0937fc66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/197970872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"LOW\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NORMAL\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HIGH\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCholesterol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCholesterol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"LOW\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NORMAL\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HIGH\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.BP = pd.Categorical(dataset.BP, [\"LOW\", \"NORMAL\", \"HIGH\"], ordered=True)\n",
    "\n",
    "dataset.Cholesterol = pd.Categorical(dataset.Cholesterol, [\"LOW\", \"NORMAL\", \"HIGH\"], ordered=True)\n",
    "\n",
    "dataset.BP = dataset.BP.cat.codes\n",
    "dataset.Cholesterol = dataset.Cholesterol.cat.codes\n",
    "\n",
    "\n",
    "features = dataset.iloc[:, :-1]\n",
    "targets = dataset.iloc[:, -1]\n",
    "\n",
    "features = pd.get_dummies(features, columns=['Sex'], prefix=\"Gender\", prefix_sep=\": \")\n",
    "# targets = pd.get_dummies(targets, columns=['Drug'], prefix=\"Drug type\", prefix_sep=\": \")\n",
    "# debug lines\n",
    "# print(dataset.head())\n",
    "# print(features)\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876aa52",
   "metadata": {},
   "source": [
    "### Split dataset for training and test (part5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4edd57eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/852666182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features.values, targets.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301fab52",
   "metadata": {},
   "source": [
    " ### Train using Gaussian Naive Bayes Classifie (part6a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159367d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/1954607740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgaussian_naive_bayes_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgaussian_naive_bayes_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "gaussian_naive_bayes_training = GaussianNB()\n",
    "gaussian_naive_bayes_training.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb83b5",
   "metadata": {},
   "source": [
    " ### Train using  Decision Tree (part6b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03081f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/2364746380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_leaf_nodes=3, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654f2418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/883808846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                      'min_samples_split': (2, 3, 7)}\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf_topdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_DT_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf_topdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"c)\")\n",
    "top_DT_parameters = {'criterion': ['entropy', 'gini'],\n",
    "                     'max_depth': (2, 4), \n",
    "                     'min_samples_split': (2, 3, 7)}\n",
    "\n",
    "clf_topdt = GridSearchCV(clf, top_DT_parameters)\n",
    "\n",
    "clf_topdt.fit(X_train, y_train)\n",
    "\n",
    "pred_result_gridsearch = clf_topdt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f27e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Perceptron' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/1288862097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"d)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf_perceptron\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclf_perceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred_result_perceptron\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_perceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Perceptron' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"d)\")\n",
    "\n",
    "clf_perceptron = Perceptron()\n",
    "clf_perceptron.fit(X_train, y_train)\n",
    "pred_result_perceptron = clf_perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b1fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/3756211943.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"e)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf_mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logistic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclf_mlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred_result_mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_mlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"e)\")\n",
    "\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "pred_result_mlp = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4911e7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/3730059664.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   'solver': ('adam', 'sgd')}\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclf_top_mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_mlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_MLP_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mclf_top_mlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpred_result_top_mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_top_mlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"f)\")\n",
    "\n",
    "top_MLP_parameters = {'activation': ('logistic', 'tanh', 'relu', 'identity'),\n",
    "                  'hidden_layer_sizes': ((30, 50), (10, 10, 10)),\n",
    "                  'solver': ('adam', 'sgd')}\n",
    "\n",
    "clf_top_mlp = GridSearchCV(clf_mlp, top_MLP_parameters)\n",
    "clf_top_mlp.fit(X_train, y_train)\n",
    "pred_result_top_mlp = clf_top_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd53c8",
   "metadata": {},
   "source": [
    "## Part 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd49d2",
   "metadata": {},
   "source": [
    " #### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbebf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\n\\n\\n\\n\\t**********************************\\n\")\n",
    "f.write(\"\\n\\tGaussian Naive Bayes Classifier\\n\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05fd3fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/1954607740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgaussian_naive_bayes_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgaussian_naive_bayes_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "gaussian_naive_bayes_training = GaussianNB()\n",
    "gaussian_naive_bayes_training.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052c93c",
   "metadata": {},
   "source": [
    "#### the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27856a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/1864825785.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drugs-performance.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nConfusion Matrix: \\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_naive_bayes_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nConfusion Matrix: \\n\")\n",
    "y_predicted = gaussian_naive_bayes_training.predict(X_test)\n",
    "f.write(repr(confusion_matrix(y_test, y_predicted)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e2d0e",
   "metadata": {},
   "source": [
    "#### The precision, recall, and F1-measure for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383b854a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17128/3765925819.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drugs-performance.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nThe precision, recall, and F1-measure\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"DrugA\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"DrugB\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"DrugC\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"DrugX\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"DrugY\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nThe precision, recall, and F1-measure\\n\")\n",
    "f.write((classification_report(y_test, y_predicted,target_names=[\"DrugA\",\"DrugB\",\"DrugC\",\"DrugX\",\"DrugY\"])))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8216c4",
   "metadata": {},
   "source": [
    "#### the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"bbc-performance.txt\", \"a\")\n",
    "f.write(\"\\nAccuracy, macro-average F1 and weighted-average F1:\\n\")\n",
    "f.write(\"Accuracy score: \" + repr(accuracy_score(y_test, y_predicted)) +\"\\n\")\n",
    "f.write(\"Macro F1 average: \" + repr(f1_score(y_test, y_predicted, average='macro'))+\"\\n\")\n",
    "f.write(\"Weighted F1 average: \" + repr(f1_score(y_test, y_predicted, average='weighted'))+\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7bd504",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5de718",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\n\\n\\n\\n\\t**********************************\\n\")\n",
    "f.write(\"\\n\\tDecision Tree\\n\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_leaf_nodes=3, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59885a2c",
   "metadata": {},
   "source": [
    "#### the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931404ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nConfusion Matrix: \\n\")\n",
    "y_predicted = clf.predict(X_test)\n",
    "f.write(repr(confusion_matrix(y_test, y_predicted)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4527c",
   "metadata": {},
   "source": [
    "#### The precision, recall, and F1-measure for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nThe precision, recall, and F1-measure\\n\")\n",
    "f.write((classification_report(y_test, y_predicted,target_names=[\"DrugA\",\"DrugB\",\"DrugC\",\"DrugX\",\"DrugY\"])))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45260f69",
   "metadata": {},
   "source": [
    "#### the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"bbc-performance.txt\", \"a\")\n",
    "f.write(\"\\nAccuracy, macro-average F1 and weighted-average F1:\\n\")\n",
    "f.write(\"Accuracy score: \" + repr(accuracy_score(y_test, y_predicted)) +\"\\n\")\n",
    "f.write(\"Macro F1 average: \" + repr(f1_score(y_test, y_predicted, average='macro'))+\"\\n\")\n",
    "f.write(\"Weighted F1 average: \" + repr(f1_score(y_test, y_predicted, average='weighted'))+\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db56930",
   "metadata": {},
   "source": [
    "### Top - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a93d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\n\\n\\n\\n\\t**********************************\\n\")\n",
    "f.write(\"\\n\\tTop Decision Tree\\n\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_DT_parameters = {'criterion': ['entropy', 'gini'],\n",
    "                     'max_depth': (2, 4), \n",
    "                     'min_samples_split': (2, 3, 7)}\n",
    "\n",
    "clf_topdt = GridSearchCV(clf, top_DT_parameters)\n",
    "\n",
    "clf_topdt.fit(X_train, y_train)\n",
    "\n",
    "pred_result_gridsearch = clf_topdt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00946d35",
   "metadata": {},
   "source": [
    "#### the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nConfusion Matrix: \\n\")\n",
    "y_predicted = clf_topdt.predict(X_test) ========================== CHECK TO SEE IF ITS CORRECT clf_topdt or pred_result_gridsearch\n",
    "f.write(repr(confusion_matrix(y_test, y_predicted)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5c11d",
   "metadata": {},
   "source": [
    "#### The precision, recall, and F1-measure for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b22f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nThe precision, recall, and F1-measure\\n\")\n",
    "f.write((classification_report(y_test, y_predicted,target_names=[\"DrugA\",\"DrugB\",\"DrugC\",\"DrugX\",\"DrugY\"])))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8255114",
   "metadata": {},
   "source": [
    "#### the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"bbc-performance.txt\", \"a\")\n",
    "f.write(\"\\nAccuracy, macro-average F1 and weighted-average F1:\\n\")\n",
    "f.write(\"Accuracy score: \" + repr(accuracy_score(y_test, y_predicted)) +\"\\n\")\n",
    "f.write(\"Macro F1 average: \" + repr(f1_score(y_test, y_predicted, average='macro'))+\"\\n\")\n",
    "f.write(\"Weighted F1 average: \" + repr(f1_score(y_test, y_predicted, average='weighted'))+\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef6907",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\n\\n\\n\\n\\t**********************************\\n\")\n",
    "f.write(\"\\n\\tPerceptron\\n\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69316537",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_perceptron = Perceptron()\n",
    "clf_perceptron.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536aa31",
   "metadata": {},
   "source": [
    "#### the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nConfusion Matrix: \\n\")\n",
    "y_predicted = clf_perceptron.predict(X_test)\n",
    "f.write(repr(confusion_matrix(y_test, y_predicted)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f20c993",
   "metadata": {},
   "source": [
    "#### The precision, recall, and F1-measure for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nThe precision, recall, and F1-measure\\n\")\n",
    "f.write((classification_report(y_test, y_predicted,target_names=[\"DrugA\",\"DrugB\",\"DrugC\",\"DrugX\",\"DrugY\"])))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a045911",
   "metadata": {},
   "source": [
    "#### the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"bbc-performance.txt\", \"a\")\n",
    "f.write(\"\\nAccuracy, macro-average F1 and weighted-average F1:\\n\")\n",
    "f.write(\"Accuracy score: \" + repr(accuracy_score(y_test, y_predicted)) +\"\\n\")\n",
    "f.write(\"Macro F1 average: \" + repr(f1_score(y_test, y_predicted, average='macro'))+\"\\n\")\n",
    "f.write(\"Weighted F1 average: \" + repr(f1_score(y_test, y_predicted, average='weighted'))+\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec54c516",
   "metadata": {},
   "source": [
    "### Multi-Layered Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\n\\n\\n\\n\\t**********************************\\n\")\n",
    "f.write(\"\\n\\tMulti-Layered Perceptron\\n\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "clf_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e465a3",
   "metadata": {},
   "source": [
    "#### the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af677c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nConfusion Matrix: \\n\")\n",
    "y_predicted = clf_mlp.predict(X_test)\n",
    "f.write(repr(confusion_matrix(y_test, y_predicted)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c33fab9",
   "metadata": {},
   "source": [
    "#### The precision, recall, and F1-measure for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nThe precision, recall, and F1-measure\\n\")\n",
    "f.write((classification_report(y_test, y_predicted,target_names=[\"DrugA\",\"DrugB\",\"DrugC\",\"DrugX\",\"DrugY\"])))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58979a5",
   "metadata": {},
   "source": [
    "#### the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"bbc-performance.txt\", \"a\")\n",
    "f.write(\"\\nAccuracy, macro-average F1 and weighted-average F1:\\n\")\n",
    "f.write(\"Accuracy score: \" + repr(accuracy_score(y_test, y_predicted)) +\"\\n\")\n",
    "f.write(\"Macro F1 average: \" + repr(f1_score(y_test, y_predicted, average='macro'))+\"\\n\")\n",
    "f.write(\"Weighted F1 average: \" + repr(f1_score(y_test, y_predicted, average='weighted'))+\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0c0de",
   "metadata": {},
   "source": [
    "### Top-Multi-Layered Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec992a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\n\\n\\n\\n\\t**********************************\\n\")\n",
    "f.write(\"\\n\\tTop-Multi-Layered Perceptron\\n\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f03c392",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/693073595.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                   'solver': ('adam', 'sgd')}\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclf_top_mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_mlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_MLP_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mclf_top_mlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_mlp' is not defined"
     ]
    }
   ],
   "source": [
    "top_MLP_parameters = {'activation': ('logistic', 'tanh', 'relu', 'identity'),\n",
    "                  'hidden_layer_sizes': ((30, 50), (10, 10, 10)),\n",
    "                  'solver': ('adam', 'sgd')}\n",
    "\n",
    "clf_top_mlp = GridSearchCV(clf_mlp, top_MLP_parameters)\n",
    "clf_top_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f094d",
   "metadata": {},
   "source": [
    "#### the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eecdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nConfusion Matrix: \\n\")\n",
    "y_predicted = clf_top_mlp.predict(X_test)\n",
    "f.write(repr(confusion_matrix(y_test, y_predicted)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1f2f9",
   "metadata": {},
   "source": [
    "#### The precision, recall, and F1-measure for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfea3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"drugs-performance.txt\", \"a\")\n",
    "f.write(\"\\nThe precision, recall, and F1-measure\\n\")\n",
    "f.write((classification_report(y_test, y_predicted,target_names=[\"DrugA\",\"DrugB\",\"DrugC\",\"DrugX\",\"DrugY\"])))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d447f",
   "metadata": {},
   "source": [
    "#### the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"bbc-performance.txt\", \"a\")\n",
    "f.write(\"\\nAccuracy, macro-average F1 and weighted-average F1:\\n\")\n",
    "f.write(\"Accuracy score: \" + repr(accuracy_score(y_test, y_predicted)) +\"\\n\")\n",
    "f.write(\"Macro F1 average: \" + repr(f1_score(y_test, y_predicted, average='macro'))+\"\\n\")\n",
    "f.write(\"Weighted F1 average: \" + repr(f1_score(y_test, y_predicted, average='weighted'))+\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d580bb4",
   "metadata": {},
   "source": [
    "## Step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de411098",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_15488/252180032.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\andre\\AppData\\Local\\Temp/ipykernel_15488/252180032.py\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    Macro_F1_average +=\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "top_MLP_parameters = {'activation': ('logistic', 'tanh', 'relu', 'identity'),\n",
    "                  'hidden_layer_sizes': ((30, 50), (10, 10, 10)),\n",
    "                  'solver': ('adam', 'sgd')}\n",
    "y_predicted = clf_top_mlp.predict(X_test)\n",
    "for i in range(10):\n",
    "    clf_top_mlp = GridSearchCV(clf_mlp, top_MLP_parameters)\n",
    "    clf_top_mlp.fit(X_train, y_train)\n",
    "    Macro_F1_average += f1_score(y_test, y_predicted, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bb6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
